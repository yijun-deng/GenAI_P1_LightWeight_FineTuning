{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: **LoRA**\n",
    "* Model: **GPT-2**\n",
    "* Evaluation approach: **The `evaluate` method with the Hugging Face `trainer`**\n",
    "* Fine-tuning dataset: The **emotion** dataset from **DAIR-AI**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, Trainer, TrainingArguments\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525ea4f4",
   "metadata": {},
   "source": [
    "Load and tokenize ***emotion*** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4935cb4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb73eaebeff4f6a8bff4dbe6edfd97e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"emotion\")\n",
    "splits = [\"train\", \"validation\", \"test\"]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", \n",
    "                                          num_labels=6,\n",
    "                                          id2label={0: \"sadness\", 1: \"joy\", 2: \"love\", 3: \"anger\", 4: \"fear\", 5: \"surprise\"},\n",
    "                                          label2id={\"sadness\": 0, \"joy\": 1, \"love\": 2, \"anger\": 3, \"fear\": 4, \"surprise\": 5}\n",
    "                                         )\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "tokenized_dataset = {}\n",
    "for split in splits:\n",
    "    tokenized_dataset[split] = dataset[split].map(lambda x: tokenizer(x[\"text\"], padding=\"max_length\", truncation=True), batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7547c8d7",
   "metadata": {},
   "source": [
    "Load ***gpt2*** model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d62c3c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"gpt2\", \n",
    "                                                           num_labels=6,\n",
    "                                                           id2label={0: \"sadness\", 1: \"joy\", 2: \"love\", 3: \"anger\", 4: \"fear\", 5: \"surprise\"},\n",
    "                                                           label2id={\"sadness\": 0, \"joy\": 1, \"love\": 2, \"anger\": 3, \"fear\": 4, \"surprise\": 5})\n",
    "\n",
    "# set the pad token of the model's configuration\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9aec2c",
   "metadata": {},
   "source": [
    "Define ***Hugging Face trainer*** and evlauate the default model on ***test*** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 02:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 2.8372974395751953, 'eval_accuracy': 0.0925, 'eval_runtime': 166.9142, 'eval_samples_per_second': 11.982, 'eval_steps_per_second': 0.749}\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./results_without_finetuning\",\n",
    "        evaluation_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
    "        per_device_eval_batch_size=16,\n",
    "    ),\n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    compute_metrics = compute_metrics\n",
    ")\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"Evaluation results: {eval_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd51ce9",
   "metadata": {},
   "source": [
    "Load ***lora*** configuration and create ***PEFT*** model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "894046c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/tuners/lora.py:475: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "config = LoraConfig(\n",
    "        r=16,  # Rank of the low-rank adaptation\n",
    "        lora_alpha=32,  # Scaling factor for the LoRA updates\n",
    "        lora_dropout=0.1,  # Dropout rate for LoRA layers\n",
    "        bias=\"none\",  # Specify how to handle biases in the model\n",
    "        task_type=\"SEQ_CLS\"  # Task type for sequence classification\n",
    "    )\n",
    "\n",
    "lora_model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbabf60a",
   "metadata": {},
   "source": [
    "Train the ***PEFT*** model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4d4c908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4000' max='4000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4000/4000 57:24, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.175800</td>\n",
       "      <td>1.113386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4000, training_loss=1.4518275909423828, metrics={'train_runtime': 3445.3641, 'train_samples_per_second': 4.644, 'train_steps_per_second': 1.161, 'total_flos': 8420233052160000.0, 'train_loss': 1.4518275909423828, 'epoch': 1.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_lora = Trainer(\n",
    "    model=lora_model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./results_with_finetuning\",\n",
    "        learning_rate=2e-5,\n",
    "        evaluation_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
    "        save_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        num_train_epochs=1,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['validation'],\n",
    "#     compute_metrics = compute_metrics\n",
    ")\n",
    "\n",
    "trainer_lora.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b2cde96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 02:54]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.1133863925933838,\n",
       " 'eval_runtime': 174.7337,\n",
       " 'eval_samples_per_second': 11.446,\n",
       " 'eval_steps_per_second': 2.861,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_model.save_pretrained(\"gpt2-lora\")\n",
    "\n",
    "trainer_lora.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from peft import AutoPeftModelForSequenceClassification\n",
    "\n",
    "lora_model_eval = AutoPeftModelForSequenceClassification.from_pretrained(\"gpt2-lora\", num_labels=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 02:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 1.1009926795959473, 'eval_accuracy': 0.596, 'eval_runtime': 172.4179, 'eval_samples_per_second': 11.6, 'eval_steps_per_second': 0.725}\n"
     ]
    }
   ],
   "source": [
    "# set the pad token of the model's configuration\n",
    "lora_model_eval.config.pad_token_id = lora_model_eval.config.eos_token_id\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=lora_model_eval,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./results_with_finetuning1\",\n",
    "        evaluation_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
    "        per_device_eval_batch_size=16,\n",
    "    ),\n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    compute_metrics = compute_metrics\n",
    ")\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"Evaluation results: {eval_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a0f7dc",
   "metadata": {},
   "source": [
    "Accuracy on test dataset ***before*** fine tuning: ***0.0925*** \\\n",
    "Accuracy on test dataset ***after*** fine tuning: ***0.596***\n",
    "\n",
    "After only 1 epoch of fine tuning, the evaluation accuracy on test dataset has been improved from ***0.0925*** to ***0.596***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
